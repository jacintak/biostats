---
title: "Statistical modelling Part 1"
output: 
    learnr::tutorial:
      theme: readable
      progressive: true
      allow_skip: false
runtime: shiny_prerendered
subtitle: "2021"
description: "2021 Practical 4 remote version"
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE, comment = NA)
tutorial_options(exercise.lines = 5)
tutorial_options(exercise.completion = FALSE)
```

## How to use this worksheet

This worksheet is an interactive document run through RStudio. It is made using the R package `learnr`, which you installed before the prac. The worksheet has interactive code chunks that you can use to enter `R` code and quizzes to test yourself - which makes this more fun than a regular word document or PDF and lets you practice R coding.

You can interact with this worksheet through the Tutorial tab in RStudio. This window can be resized and expanded. However, I recommend clicking the pop out button (in between the home icon and the stop icon) to open the tutorial in a separate window. 

***

**Code chunks**  
Code chunks are independent of the main RStudio Environment. Anything you type here will not be saved to memory, but you won't need to. Try it:  
*Here's a simple exercise with an empty code chunk provided for entering the answer. Click __Run Code__ to run the code. The __Hint__ button will tell you a hint. If you are really stuck, the last hint may be the solution.*

Write the R code required to add two plus two (the answer should be 4):

```{r test, exercise=TRUE, exercise.eval=TRUE, exercise.lines = 5}

```

```{r test-hint}
You need a + somewhere. You do not need =
```

```{r test-solution}
2+2
```

You can use RStudio and R scripts at the same time for trying things out or taking notes. 

***

**Quizzes**  
**Quizzes here are not part of the CA.** The questions are meant to check you understand the material and your answers are not visible to anyone else. The CA is accessed separately.

*Here's a quiz. Try it out to see how it works. Click __submit__ and it will tell you what you got correct. What happens when you put an incorrect answer in?*
```{r test-quiz}
quiz(
question(
  "What colour is a red squirrel?",
  answer("Red", correct = TRUE),
  answer("Brown"),
  answer("Grey"),
  answer("Black"),
  allow_retry = TRUE,
  random_answer_order = TRUE
),
question_text(
  paste("What is the answer to the above coding exercise?"),
  answer("4", correct = TRUE),
  allow_retry = TRUE
),
question_checkbox(
  "Which of these are not fish? Select all that apply.",
  answer("Seadragon"),
  answer("Starfish", correct = TRUE),
  answer("Jellyfish", correct = TRUE),
  answer("Cuttlefish", correct = TRUE),
  answer("Alligator gar"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
)
```

***

Well done!  
Your answers are saved if you open the tutorial again. You can reset your answers by clicking **Start Over** at the end of the menu. You can run these tutorials any time you like if you want to practice again. Although you can come back to this tutorial at any time, I recommend taking your own notes for your reference. There are also discussion questions in bold that you should think about or write down an answer.  

Click **Next Topic** to progress to the practical instructions.  
You can navigate between topics using the buttons or the menu. You may not be able to skip ahead if you haven't completed all the exercises.

***

## Introduction to statistical modelling

Welcome! In the last two practicals (4 and 5) and in three lectures we will be looking at statistical modelling. 

We have progressed beyond the realm of doing stats by hand and where t-tests are not appropriate for the types of data we will look at or the hypotheses we test. R will be the tool we will use.

In these sessions, we will focus on the practical aspects of *applying* statistics (implementation & interpretation) with real data - not on the theory or mathematical proofs - in fact, nearly all the relevant theory has been introduced to you in previous lectures. Equations are kept to a minimum (promise). 

The practicals and lectures will feed off each other and these will also build upon the previous lectures and practicals. I expect you to be up to date with the module material. As this practical comes first, we will start with an introduction to statistical modelling that we will continue in the lectures.

The demonstrators are available if you have questions about the concepts or have technical issues with running the practical. Do talk to them. They will be checking in and making sure you are keeping to time.

Dr Jacinta Kong

***

### What is statistical modelling?

Statistical modelling is an umbrella term in statistics, it can refer to many things and broadly speaking is a philosophical way of thinking about data.

A definition:

> Statistical models are logical mathematical or statistical descriptions of what we believe to be important in a biological system. 

Philosophically, biologists use models to describe the real world in (relatively!) simple ways. Models are (often abstract or reductionist) representations of reality.

We use models to:

 * Make sense of a complex and messy real world and its data
     * Formulate new theories
 * Test our understanding of a biological system
     * Formulate hypotheses
     * Make predictions
 * Make evidence-based decisions
     * Run simulations - "what if...?", what happens if we change something?
 
If our model doesn't match what we observe from empirical data, that's OK! We can refine our model (our hypothesis) to better match what we observe. **That's the Scientific Method.** Remember, doing science isn't about "proving" a hypothesis or being "right" - it's when we "fail" or are wrong that progress happens.

We will see in the lectures that there is a trade-off between precision, generality and realism of models - there is no, one "perfect" model.

> To paraphrase a quote: all models are wrong but some can be useful

***

### Variables vs parameters

Distinguishing between variables and parameters is important in statistics, particularly for modelling.

**Variables** - These are quantities that change with each iteration of a statistical model. E.g. the predictor (independent) variable and the response (dependent) variable.  

**Parameters** - These are quantities that do not change with each iteration of a statistical model. They are often a constant and often represent the assumptions about our biological system we make to model it. If we change the fundamental assumptions of the model, then the *value* of the parameter may change. Often the value of the parameter is **unknown** to us and need to be *parametrised* from empirical data.  

A variable could switch to being a parameter or vice versa depending on the experimental design and hypothesis tested, which in turn determines the statistical model. These decisions should be made when planning an experiment, not during or afterwards. 

We will go through the process of parametrising in the next practical and in the lectures.

***

### Types of models

Models can be characterised in several ways.

Depending on what they describe:

 * **Theoretic models** describe processes - explored here
 * **Empirical models** describe data - explored in lectures and in practical 5

Some biological systems can be described both ways.

***
 
Models can be placed on a spectrum of simple to complex, and specific to general.

   * A simple and general model are analytical models like functional responses (discussed here)
   * A simple and specific model are linear regression models (discussed in lectures)
   * A complex and general model are global climate forecasting models
   * A complex and specific model are phenomenological models (e.g. growth of a species)
 
***

Models can also be described based on their precision, realism and generality. But these trade-off - No one model can perfectly capture all these qualities.
 
> The best model to use depends on the intended question.

***

*All types* of models are based on assumptions or require information about the biological system. This has some limitations:

 * The assumptions may be too simplistic for complex systems (most biological systems)
 * We may not know enough information about the biological system to make a good model
 * The model is too reductionistic or abstract (i.e. unrealistic)
 * There is uncertainty we cannot eliminate
 
We will see these concepts again in the lectures and in practice here.

```{r modelling-quiz}
quiz(
question(
  "Which of these questions would not need a statistical model to answer?",
  answer("All of these involve statistical models", correct = TRUE),
  answer("Deciding where to invest finances"),
  answer("Estimating when students can return to face-to-face learning"),
  answer("Forecasting tomorrow's weather"),
  allow_retry = TRUE,
  random_answer_order = TRUE
),
question_radio("Statistical models aim to accurately and precisely describe reality as it is",
  answer("False", correct = TRUE),
  answer("True"),
  allow_retry = TRUE
)
)
```

***

### Practical information

In these practicals we will look at a theoretic model of a pathogen response (predator-prey interaction). The aim is to understand how statistical models can be applied to biological data. 

The majority of this practical will focus on the practicalities of designing experiments and collecting data, which we covered earlier in the module. The data collected in this practical must be submitted to Blackboard and will be used in the next practical.

I recommend taking your time with these practical and the concepts because they are fundamental to biological statistics you are likely to encounter again (plus are highly relevant to your final report). There is no need to rush.

***

### Learning objectives

This practical is split into three parts with distinct learning objectives (recommended time to spend):

Part A: Building a theoretic model (20 mins)  
**Learning objectives:**

 * Know how a biological process can be described by a statistical model 
 * Understand how statistical models are applied to answer real world biological questions

Part B: Designing an experiment (20 mins)  
**Learning objectives:**

 * Apply your knowledge about experimental design and hypothesis formulation to a biological problem in practice
 
Don't spend too long on Parts A and B = move through them and the CA quickly. Part C is the most important part and will take the most time. 

Part C: Collecting data (**2 hours**) 
This is the main activity of the practical.  
**Learning objectives:** 

 * Know how to organise a spreadsheet and fill in a spreadsheet with data following the principles of tidy data
 
You will be uploading your data to Blackboard. In the next practical we will be analysing the aggregated & anonymised class data set and using that to answer CA questions.

***

### Continuous Assessment

I recommend finishing the CA *before* Part C. The CA is worth 10% and is due at the end of the prac. There is a total of 10 marks. 

The CA aims to assess your understanding of the concepts in this practical and your ability to apply the concepts in practice.

***

## Part A: Theoretic models

In the previous practical you looked at a killer T cell digesting a pathogen. This infection response is a biological process and is analogous to a predator (e.g. a lion) hunting a prey (e.g. zebra), or a robot (a "predator") cleaning up an oil spill (its "prey").

You started to compose a Scratch model. Although the Scratch model comprises of pictures and code blocks, under the hood these blocks represent computer code, and more abstractly a mathematical processes. Thus, the Scratch model is an implementation of a statistical model of a biological system - the infection response.

This model was simple - too simple to be realistic. The killer T cell captured any and all pathogens touching it whereas in reality, a killer T cell may only target a few pathogens at a time or sequentially. This is also true for animal predators who hunt. Most predators need time to catch and process their food before their next meal.

We can conceptualise a more realistic representation of an infection response, or more abstractly a predator-prey interaction. By breaking down what we observe to be important about the infection response into variables and assumptions, we can build our own theoretic model (describing a process) of an predator-prey interaction from the ground up.


***

### What is a predator-prey interaction?

In a predator-prey interaction we have two **variables**:

1. Predator
2. Prey

If we think about what we consider to be important in a predator-prey interaction, searching for and handing prey two mutually exclusive aspects. We can then make the following statements, or assumptions, about the predator-prey interaction:

* A predator randomly searches for prey
* A predator can only "search" a fixed area per unit time (search rate)
* A predator can only eat one prey at a time - it must "process" (i.e. digest) the prey before it can begin searching for the next one (handling time)
    * Handling time and searching activity are mutually exclusive
* Prey randomly move around independently of the predator (e.g. it does not slow down or speed up when the prey is near)
* Both the predator and the prey move at the same speed and at a constant speed
* Both the predator and the prey only move within a fixed area (e.g. their habitat), they cannot leave.
* The numbers of predators and prey are fixed at the start of the experiment (i.e. they do not replicate while the model is running, prey numbers can only decrease, predator numbers stay the same)
* Each predator-prey interaction lasts a fixed amount of time (total time)

These same statements can be applied to an infection response or to any analogous scenario - merely replace "predator" and "prey" with the relevant terms.

**Would you agree with these statements? Or are they too simplistic of a complex biological system?**  

```{r assumptions}
quiz(caption = "First, a quick quiz on variables",
question(
  "What are the variables for a statistical model for a hawk predating on a pidgeon?",
  answer("The hawk and the pidgeon", correct = TRUE),
  answer("The hawk only"),
  answer("The pidgeon only"),
  answer("Neither the hawk or the pidgeon"),
  allow_retry = TRUE,
  random_answer_order = TRUE
),
question(
  "What does it mean when the killer T cell and the pathogen are described as variables in a predator-prey model?",
  answer("They are the components of interest in our infection model that change with each run of the model", correct = TRUE),
  answer("The numbers of pathogens never change in any scenario"),
  answer("The numbers of killer T cells never change in any scenario"),
  answer("They are unknown to us"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
)
```

If you thought our model is too simplistic, you are probably right *but* in modelling philosophy some degree of simplification or abstraction is perfectly acceptable because *models are only representations of reality*, they are not meant to copy the real world right down to the minutiae.

> Thus, one application of models is to consider them as hypotheses of biological systems - what we think are important components of the system.

***

### Functional responses

Infection responses, predator-prey interactions...they can be generally classified as **functional responses**. Luckily for us, there are already well known analytical (mathematical) models of functional response that we can use.

There are multiple types of functional responses (labelled with Roman numerals: I - IV). Each of these models represents a *different hypothesis* about functional responses and mathematically describes a *different relationship* between our two variables (e.g. the killer T cell and the pathogen, or a predator and its prey). The assumptions we make above are based on a **Type II functional response model** and is the one most appropriate for an infection response scenario. You can read about the full maths by running `vignette("TypeII_models")`. We won't discuss the other types but you can read about them by running `vignette("functional_responses")`. 

The Type II functional response model is a good example of a general model - it has been used to describe animal predators eating prey (e.g. Holling's disc equations) or enzymes catalysing reactions (e.g. Michaelis-Menten equation). We can also use it to describe the immune response of the previous practical. It doesn't matter what the mathematical symbols represent biologically, maths is a universal language that describes the underlying biological process. Here, we are applying it to an general predator-prey scenario.

***

```{r models-quiz}
quiz(
  question(
  "Which of these is not a rationale for using statistical models on biological data?",
  answer("To disprove a hypothesis", correct = TRUE, message = "Scientists don't 'prove' hypotheses"),
  answer("To make sense of biological patterns"),
  answer("To make new theories"),
  answer("To guide future research"),
  allow_retry = TRUE,
  random_answer_order = TRUE
),
question_checkbox(
  "Which of these words describe our predator-prey model? Select all that apply.",
  answer("Complex"),
  answer("Simple", correct = TRUE),
  answer("Analytical", correct = TRUE),
  answer("Theoretic", correct = TRUE),
  answer("Empirical"),
  allow_retry = TRUE,
  random_answer_order = TRUE
),
  question(
  "Which of these are not limitations of statistical models?",
  answer("We consider alternative scenarios", correct = TRUE),
  answer("Models need a lot of data we may not have"),
  answer("Models are too reductionistic"),
  answer("Models have uncertainties we cannot always control"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
)
```

***

### A Type II functional response

**How would you describe the below Type II relationship in words in a results section of a lab report?**  

```{r funct_resp, echo=FALSE, fig.cap= "Type II functional response of an infection response"}
prey <- seq(0, 60, 5)
type2 <- (prey*0.7)/(1+(prey*0.7*0.15))
plot(type2~ prey,
     type = 'l',
     lwd = 4,
     xlab = "prey density", ylab = "Number of prey eaten",
     xaxt='n', yaxt='n')
```


Maybe something like:   
"The number of prey eaten rapidly increases at low prey densities and gradually plateaus to a maximum number of prey eaten at higher prey densities."

The mathematical model of the figure above is:

$$H_a=\ \frac{a\times H\times T_{total}}{1+a\times H\times T_h}$$

You should read the full derivation in the documentation file to see how we've turned our assumptions into mathematical expressions - run `vignette("TypeIImodels")` in Console or via the Packages tab (click biostats.tutorials -> User guides).

Let's go through what the letters and numbers mean and how they link to our model assumptions.

 * $H$ is the number of prey within a fixed area (prey density, number per area). This is our predictor variable that we decide before our experiment
 * $a$ is the search area per unit time of a prey. This is a parameter that we do not know and that we calculate from our data.
 * $H_a$ is the number of prey captured. We record this at the end of our experiment as our response variable.
 * $T_{total}$ is the total time a predator spent hunting prey (time). This is a constant that we decide before we start the experiment based on our assumptions.
 * $T_h$ is the time a predator spends digesting a single prey (time per prey). This is a parameter that we do not know and that we calculate from our data. In functional response models, this is called handling time.

You'll see that we know the value of some of these parameters already and some we need to calculate from our data.

**Variables or parameters? Which is which in our model?**

### Quiz

```{r constants}
question_checkbox(
  "Which of these parameters are unknowns we need to calculate from our data? Select all that apply",
  answer("Ha"),
  answer("Th", correct = TRUE),
  answer("T total"),
  answer("a", correct = TRUE),
  answer("H"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

### Finding our unknown parameters

How do we estimate these unknown parameters from our data (e.g from the figure above)?  
Actually, the hyperbolic nature of the Type II makes it challenging to extract this information - and certainly beyond the expectations of this module. *But* we can use mathemagics to turn this hyperbolic relationship into a straight line by a process called *linearising*. And straight lines are easier to manipulate or interpret - something we expect you to be able to do in this module.

The linearised Type II equation is: 
$$\frac{1}{H_a}=\ \frac{1}{a}\times\frac{1}{H\times T_{total}}+\frac{T_h}{T_{total}}$$
The full derivation is accessible in `vignette("TypeIImodels")`, we won't go though how this is derived here, but you *do* need to understand this equation:

 * $\frac{1}{H_a}$ is the inverse of our response variable - the number of prey eaten 
 * $\frac{1}{a}$ is the inverse of our unknown search rate parameter
 * $\frac{1}{H \times T_{total}}$ is the inverse of our predictor variable (prey density) and the total predator-prey interaction time
 * $\frac{T_h}{T_{total}}$ is our unknown handling time divided by the total predator-prey interaction time

**Does the overall structure of the equation look familiar to you? (maybe from high school maths)**

The graph looks like this:
```{r tyepe2line, echo = FALSE, fig.cap= "Linearised type II functional response of an infection response"}
prey <- seq(0, 0.25, 0.01)
type2 <- seq(0, 1, length.out = length(prey))
plot(type2 ~ prey , type = 'l', lwd = 4, ylab = "1/Ha, Prey eaten", xlab = "1/H Total time, Prey density",
     xaxt='n', yaxt='n')
```

The linearised function has the general form $y = \beta_1 x + \beta_0$ which is a straight line. $y$ is the response variable, $x$ is the predictor variable, $\beta_1$ is the slope or gradient of the line, and $\beta_0$ is the intercept of the line. We will see this notation again in the lectures.

### Quiz

```{r quiz2}
quiz(
  question(
  "Which of these represents the slope of a general straight line?",
  answer("y"),
  answer("$\\beta_1$", correct = TRUE),
  answer("x"),
  answer("$\\beta_0$"),
  allow_retry = TRUE,
  random_answer_order = TRUE
),
  question(
  "Which of these represents is the response variable of a general straight line?",
  answer("$\\beta_0$"),
  answer("y", correct = TRUE),
  answer("x"),
  answer("$\\beta_1$"),
  allow_retry = TRUE,
  random_answer_order = TRUE
))
```

This linear form allows us to estimate the coefficients for the linear equation where y = $\frac{1}{H_a}$ and x = $\frac{1}{H\times T_{total}}$.  

From the linearised Type II equation we can see that:  
$$Slope=\ \frac{1}{a}$$  
$$Intercept=\ \frac{T_h}{T_{total}}$$  

We can calculate the slope and intercept from regression and then do some algebra to find $a$ and $T_h$:  
$$a=\frac{1}{slope}$$ 
and
$$T_h = T_{total} \times intercept$$

Now we have our model, we can then ask "what if...?". What happens if we change things in the model? 

>For the rest of the practical we will look at the question:  
>**What happens to the number of prey a predator can eat when the number of prey in an area (the density) increases?**  

Unlike the previous practical, we are going to investigate this question by conducting a real experiment and make the most of in-person teaching by working in groups! But it is possible to build an equivalent simulation in Scratch.

Now we have our research question and a model, we implicitly have our hypotheses. 

**Write down a null (H0) and alternative (H1) hypothesis before moving on to the next section.**  
If you are not sure how to formulate a hypothesis, look back at previous material, then ask a demonstrator.

***

##

That's the end of Part A. Check in with your demonstrator. Take a break. Stand up. Shake your limbs. Breathe.

```{r break-quiz}
question(
  "Who lives in a pineapple under the sea?",
  answer("Spongebob Squarepants", correct = TRUE),
  answer("Patrick Star"),
  answer("Squidward Tentacles"),
  answer("Sandy Cheeks"),
  random_answer_order = TRUE
)
```

You're doing great!

***

## Part B: Designing an experiment

### Hypotheses

How do your hypotheses compare to these?

H0: There is no relationship between prey density and number of prey eaten  
H1: There is a positive linear relationship between prey density and number of prey eaten

Notice how the hypotheses is worded and the language used. **The wording of your hypothesis will dictate the best experimental design and statistical analysis to test your hypothesis!** Choose wisely. 

The alternative hypothesis describes the direction but not the strength of the relationship. If you are less certain about your predicted outcomes you could be less specific if you wanted to (e.g. not describing the direction of the relationship if the expected relationship could also be negative). 

There are no limits to how many hypotheses you have. You could have three hypotheses, a null and two alternatives - one for a positive relationship and one for a negative relationship. **Remember, as scientists we never try to "prove" hypotheses. We aim to gather evidence and see whether the evidence supports our hypothesis.**

It's good to be specific in your hypothesis if it is plausible in your biological system. For example, if we are testing whether a vaccine induces an immune response, the resulting immune response can only be positive - a negative immune response (i.e. becoming more susceptible to disease) is implausible (and unfortunate).

Keep your hypothesis as simple as possible to investigate what you are interested in, in your biological system. A more complex hypothesis means a more complex statistical analysis is needed.

Conducting a simple statistical analysis on a complex hypothesis and experimental design means that there is variation in your data that is not accounted for and could be affecting your response variable - it increases the chances of making a type II error (the meaningful biological relationship is hidden under statistical noise).

> **When in doubt, keep it simple.** 

***

### The predator-prey Scratch simulation

In the previous practical you looked at building a Scratch model with a predator (a killer T cell) and some prey (invading pathogens). Your response variable was time taken to destroy all the pathogens and the predictor variable was the number of pathogens (pathogen density).

In this practical we have a slightly different hypothesis and thus a different experimental design. The predictor variable is the same but the response variable is the number of pathogens destroyed at the end of a fixed amount of time. We also have additional assumptions about functional responses that change how the simulation should behave - searching and handling prey are independent and mutually exclusive.

You don't have to modify the previous practical simulation yourself... I have done this for you.

You have been provided with a Scratch model you need to use to generate data for this practical and the next. This Scratch model is based on the previous practical but because our model of the biological system is more realistic and complex, our Scratch model is also more complex. You can compare the two and see what has changed.

You do not need to change any aspect of the predator sprite. When the predator eats a prey it will stop searching (moving) until it has finished digesting its prey and resumes searching. This behaviour is one of our model assumptions and is controlled by a variable called digesting but it's not important to track it.

Under the prey sprite tab you will see three code blocks arranged from top to bottom. They are:

* Top: Set user defined variables for the simulation
    * prey density - the default is 20 but **this number needs to be changed because it's our predictor variable**, $H$ 
    * efficiency - the default is 1 but we will ignore it for now
* Middle: Set up the counters and timer
    * prey_density is the number of prey our predator has destroyed, $H_a$
    * digesting is the foraging state of the predator, you can ignore this but it is an implementation of our assumptions that destroying and searching for prey are mutually exclusive activities
    * total_time is the duration of the infection response, $T_h$. This should be 60 seconds (1 minute).
* Bottom: This describes the behaviour of the prey The prey will move around randomly until it touches the predator. If the predator is hungry, the prey is destroyed and the predator becomes full (the digesting variable). If the predator is full, then the prey lives.

When you click the green flag you will see two counters: a count down timer and the number of prey caught. The predator and prey sprites move around randomly within the fixed arena. The simulation stops when either the timer reaches zero or when all prey are caught and the original prey density is displayed. Press the stop button to reset the simulation.

Now we have our research question and a model, we implicitly have our hypotheses. 

**Write down a null (H0) and alternative (H1) hypothesis before moving on to the next section.**

If you are not sure how to formulate a hypothesis, look back at previous material, then ask a demonstrator.

***

### Identifying treatments 

Experiments consist of variables that are *controlled* or *manipulated*. The manipulated variables are usually predictor variables. Controlled variables are other influential variables that may affect the response variable in ways that might mask or accentuate the effect of the predictor variable on the response variable. We control as many possible variables as possible to make sure what we observe is the true effect of the predictor variable of interest.   

 * If we cannot control a variable, the least we can do is record it as a co-variate and apply more complex stats to account for the additional variable.   
 * If we don't keep a comprehensive record, then we risk the co-varying variable **confounding** the true effect of the predictor variable, adding uncontrolled variation (decreasing the chance of getting a significant P value) and increasing the risk of Type I or II error.

We change the prey densities with each run of the experiment because it is the predictor variable. The different values of prey density is our **treatment**.

How many prey densities should you use? **Generally, the more treatments, the better your data may capture some true biological relationship.** But more treatments means more work, time and effort! You need at least two treatments (two observations) to fit a straight line to data but there is no hard or fast rule for deciding these things. 

**For the purpose of this practical, we will decide on 10 treatments of prey density (do a minimum of 5 if you are running out of time). You are free to choose any 10 numbers from a range of 1 to 100.** 

We will collate the entire class' data so you don't have to choose the same numbers. We aim for consistency and balance when designing experiments, so your treatments should be equally spaced out. For example, with equal increments.

***

### Replication, replication, replication

Replication is really important to increase the accuracy and precision of our data and make sure our results are not due to random chance. **Generally, the more replication the better! Again, the trade-off is more work, time, effort or computing power.**. It also reduces the chances of making a type 1 or type 2 error. 

**For the purpose of this practical, we will use 3 replicates of prey density.** Three is usually a minimum number of replications. In a real-world scientific study, you may see higher replications.  

A replication of 3 means that we need to repeat our experiment three times for every value of the treatment. Each replication should be independent of the others. Otherwise you risk *pseudoreplication* - not replicating when you think you are.

***

### Identifying constant parameters


In our experiment we have 1 predator moving at a constant speed (or tapping at a constant rate). These are constants that does not change - doing so would violate the assumptions of our model or turn these parameters into variables.

Total foraging time is another constant. For simplicity, we will use a value of **1 minute** only so that we can divide by 1 and it makes our maths easier.

The number of predators, speed and total time are all *parameters* and they are *constant* in a single experiment. Changing these would fundamentally change the experimental design and hypotheses tested. Changing these but keeping our hypotheses the same would be introducing additional variation into our data and increase the chance of making a type 2 error. Thus, sometimes parameters become variables; it all depends on the aim of the study.

Although these constant parameters are unknown to us, we want to know their values to use the analytical model but we need empirical data to fit to our analytical model. We will estimate these values using statistical models next practical to complete the equation:

$$H_a=\ \frac{a\times H\times T_{total}}{1+a\times H\times T_h}$$

> Remember: keep it simple! A more complex statistical analysis cannot fix issues arising from a badly designed experiment.

***
##

```{r quiz3}
quiz(caption = "Have you been paying attention?",
  question_text(
    paste("How many treatments are we using?"),
    answer("10", correct = TRUE),
    allow_retry = TRUE
  ),
  question_text(
    paste("How many replications are we using?"),
    answer("3", correct = TRUE),
    allow_retry = TRUE
  ),
  question_text(
    paste("How many hypotheses are we testing?"),
    answer("2", correct = TRUE),
    allow_retry = TRUE
  ),
  question_text(
    paste("Thus, how many observations should our data set contain?"),
    answer("30", correct = TRUE),
    allow_retry = TRUE
  )
)
```

***

### What if...? 

That's not all we want to do today!

> Another use of statistical models is to explore different scenarios that represent different hypotheses.

What happens if our predator was more efficient? What would you change about the experiment to achieve this? How would this aim affect $H_a$ and the estimates of $a$ and $T_h$? For example, vaccines provide a chance for the immune system to "learn" how to eat prey (e.g. viruses). After this experience, immune systems become more efficient at destroying prey. As another example, animal predators often get better with experience, maybe they learn a more efficient foraging strategy - practice makes perfect! We can call this variable **foraging strategy**.   

The efficiency of the predator is set as a variable in Scratch called `efficiency` . In the model, the
duration of time a predator waits while digesting is a random number between 1 and 5 that is multiplied by the value of `efficiency.` For example, if digesting time was 5 and `efficiency` was 1, then the effective digesting time is $5 \times 1 = 5$ seconds. The efficiency value is a constant parameter in our simulation - it doesn’t change and applies to all runs of the simulation; changing this value changes the intended scenario.

Let’s call our original predator a naive individual with an `efficiency` value of 1. Now,
consider an experienced individual with an efficiency value of 0.5. We have changed our constant
parameter, it doesn’t fundamentally change our model assumptions but becomes a new variable that is
used to calculate the effective digesting time.

If we want to compare the number of prey captured between naive and experienced predators, we need to run the experiment again keeping everything the same but changing only the variable of interest. In addition to the hypotheses before, we have two new hypotheses:

H0: There is no difference in the number of prey captured with prey density between naive and experienced predators
H1: There is a difference in the number of prey captured with prey density between naive and experienced predators

We can formulate a more specific alternative hypothesis:
H1: Experienced predators will capture more prey

These two experiments are *independent*. If we want to compare the foraging properties between the two predators, we need to run the experiment again **keeping everything the same but changing only the variable of interest**.

In addition to the hypotheses before, we have two new hypotheses:

H0: There is no difference in the number of prey eaten with prey density between foraging strategies  
H1: There is a difference in the number of prey eaten with prey density between foraging strategies 

It's often more interesting to formulate a more specific alternative hypothesis than just the opposite of the null hypothesis if we hypothesise there's a *direction* to the effect of the new predictor variable on the response variable

**Formulate a more specific hypothesis we can use as an alternative hypothesis.**

In other words, we generally want to know if the change in predator experience *improves* their efficiency, which is demonstrated by the number of prey captured. If we used the original alternative hypothesis then we would accept that hypothesis even if the number of prey captured decreased.

As a another example, a simplistic hypothesis is not an informative or helpful conclusion if we were testing a new vaccine and the vaccine made people *more susceptible* to disease yet we would need to accept our alternative hypothesis.

> Remember, the alternative hypothesis is the outcome we would expect if there was an effect of the predictor on the response variable. The null hypothesis is what we expect when there is no effect (hence, null). Most of the time we want there to be an effect (what we hope is true about a biological system).

```{r genotype-quiz}
quiz(
  question(
    "Which of these variables are we changing to compare different foraging strategies?",
    answer("How the predator handles prey", correct = TRUE),
    answer("The number of prey"),
    answer("Prey density"),
    answer("Prey captured"),
    random_answer_order = TRUE,
    allow_retry = TRUE
  )
)
```

So we need to expand our dataset. We can add more observations to our first dataset and a new column denoting whether the predator was experienced or naive.

```{r nrow}
quiz(question_text(
    paste("Thus, how many observations should our final data set contain?"),
    answer("60", correct = TRUE, message = "All other variables and constants stay the same"),
    allow_retry = TRUE
  ),
  question_text(
    paste("How many response variables do we have?"),
    answer("1", correct = TRUE),
    allow_retry = TRUE
  ),
  question_text(
    paste("How many predictor variables do we have?"),
    answer("2", correct = TRUE, message = "Prey density and foraging strategy"),
    allow_retry = TRUE
  )
)
```


##

That's the end of Part B. We have designed an experiment and identified our hypotheses.  

> Take a break. Check in with your demonstrator. Stand up. Shake your limbs. Breathe.

```{r break-quiz2}
question_radio(
  "Who won the 1932 Great Australian Emu War?",
  answer("The Emus", correct = TRUE, message = "All hail the emu overlords!"),
  answer("The Australian Army"),
  incorrect = "All hail the emu overlords!"
  )
```

Keep it up!

***

## 


> Now do the CA and hand it in to a demonstrator for marking

Don't forget to include your name and student number. Good luck!

***

## Part C: Collecting data

Planning about collecting data *before* collecting any data will save you a lot of headache if you realise halfway through that you've made a mistake and have to start over, or that there is a better, more efficient way of organising your data. Planning is everything.

Scientists often work in teams, which means that several people might collect data. This means that every person must collect data in a consistent way so that all the data can be aggregated. It also means that what information to collect and how it is stored or shared needs to be agreed on before anyone starts. One might also need to consider any laws or regulations for how data is collected (e.g. research ethics, privacy laws). 

Having a standardised data sheet and way of data entry is key to maintain consistency and minimise data loss.

### Tidy data

Tidy data is set of principles for organising data sheets and filling in data. It is designed in a way to make data analysis easier and reduces the amount of work required to *prepare* your data for analysis.

In short: 

 * Every column is a variable
 * Every row is an observation

You can read about tidy data [here](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html).

### Long vs Wide data

There are two general ways of presenting data in a spreadsheet (or as tabbed data): 

* Long - Variables are presented in one column, the corresponding value is presented in a second column. This format can be hard to interpret
* Wide - Each variable is a separate column (many columns) and each row is a single observation. This is the way we are collecting data in class (see above criteria)

As a general rule, aim to add rows (observations) not columns and columns should be independent of each other. For example, R analyses data in columns (arrays) so treatments of a predictor variable should be in the same column rather than in separate columns (data in columns are no longer independent). I'll demonstrate this below using the `PlantGrowth` dataset in R describing the weight of plants following one of three treatments:

The dataset is already in a long format:
```{r long, echo = TRUE}
PlantGrowth 
```

An equivalent wide format shows each treatment as separate columns:
```{r wide, echo = FALSE}
data.frame(ctrl = PlantGrowth[PlantGrowth$group == "ctrl",]$weight,
          trt1 = PlantGrowth[PlantGrowth$group == "trt1",]$weight,
          trt2 = PlantGrowth[PlantGrowth$group == "trt2",]$weight)
```

In this case, the wide format would be inappropriate for analysis because each row is not an observation, but three independent observations, and each column is not an independent variable but treatment levels of one variable. We would not be able to do stats on the wide format (e.g. a t-test) because the relevant data is split over multiple columns, rather than one column. We would need to use the long format (and a t-test is inappropriate for this dataset [**Why is a t-test inappropriate and which test would be?**]). 

Sometimes we need to convert the data structure from wide to long or vice versa. We won't be needing to do this in this module. That's why we are taking care with designing our data sheet to make it easier to analyse our data with minimal post-collection data manipulation.

### Filling in a data sheet 

To help you, there is a data sheet template on blackboard you can fill in. 

Here are the rules we want you to apply here (these are not global standards and may vary elsewhere):

 * CaSe coNsistEncy in all text
     * All words including column headers should be in lower case, no spaces
 * Column headers should be informative
     * `pathogen_density` or `total_time` is good (even the mathematical notation like `H` or `Th` because it is standardised)
     * `col1` or `pd` is bad - not easy to understand (e.g. acronyms not everyone uses)
 * No empty cells
     * All cells should have a value. Put `NA` if empty
     * Every cell is a single value
 * Do not mix alphanumeric characters (e.g. l3773r5 & numb3r5)
     * Numeric columns should only contain numbers (0-9), no letters. Character strings should only contain letters (a-z), no numbers
     * Avoid special characters (e.g. (), ~, &, / etc.)
 * No spaces (called whitespace in computing)
     * No spaces between words. Use _ instead. E.g. `no_spaces`
     * No spaces before or after words
     * This rule doesn't apply to generic text fields for taking notes, comments or observations. It applies to treatments of a variable if they are described by strings, e.g. `no_fertiliser`, `yes_fertiliser`
 * Data is stored in rows and columns in a "wide" tidy format
 * All data is presented together
     * Not in multiple sheets - use a separate file if you must.
 * Data is raw
     * Meaning it is not manipulated or processed after being recorded. We will do any data processing in `R` next prac
     * All data is presented, not summarised. E.g. as means 
 * Data is presented in a portable csv format
     * Not everyone has access to Excel. What if someone uses Google Sheets? ".xlsx" files are for Excel. 
     * ".csv", comma separated files are portable across platforms, use less memory and are easy for a computer to read - save your data in this format
 * Are all the necessary columns/information included and in the right order?
     * The order doesn't always matter but in this case it does for the automatic checking script
     

***

#### Database lingo

When data is imported into a computer, the computer will classify it according to the type of data. Here are some common data types:

 * numeric - fields or cells that only contain numbers
 * string - strings of characters, i.e. text. Can be letters and numbers. Called `character` in `R`
 * date - for dates
 * logical - for logical statements, e.g. TRUE/FALSE
 
These are the main data classes characterised by `R`. There may be other types in other programs (e.g. Access, SQL). In computer science, "fields" are like variables (i.e. columns) in `R`, so "predator density" and "total time" are fields.

***

### Do your experiment & collect your data

See the table below for an example of column headers with no spaces and all cells with a single value. These are the information you need to provide in your data sheet and the type of data they are:

| column_information            	| information_type 	| description 	|
|-------------------------------	|------------------	|-------------	|

| student_numbers                	| NA          	    |   	|
| total_time 	                    | numeric          	| `1` in minutes, not seconds	|
| prey_density              	| numeric          	| NA          	|
| replicate                     	| numeric          	| NA          	|
| prey_eaten           	| numeric          	| NA          	|
| foraging_strategy            	| character        	| `naive` for no experience or `experienced` for a experienced predator |


These headers are pre-filled for you in the correct order on the template.  

The order of columns has to exactly match the order in the table. Your exact column header names can be different as long as they follow the critera above (lowercase, no spaces, informative). 

> Remember to save your data regularly.

```{r radio1, echo = FALSE}
question_radio(
  "What should be entered in the cell under the column foraging_strategy when using a predator without experience",
  answer("naive", correct = TRUE),
  answer("experienced"),
  allow_retry = TRUE
)
```

***

### Data cleaning

In data science, data usually needs to be processed before we can use it. The data needs to be checked and validated. Are all the fields entered correctly? Attention to detail is important in case it introduces mistakes in our data that may bias our analyses! How much do you trust your fellow students to have followed the previous instructions to the letter?

Checking and correcting data is called **cleaning**. We take raw data and clean it up. Sometimes data cannot be fixed (e.g. errors of unknown origin), then the conservative approach is to exclude the observation which is a shame if lots of time and effort went in to collecting it.

In the real world, data is almost never clean and cleaning often takes longer than the actual analysis! Luckily, you won't need to do it for this prac. This is partly why we want to be particular with recording data - it will make automating the processes faster.

Here is the function I will use to check a data sheet and decide to keep or discard it based on whether it meets *all* the data criteria. You have learnt about functions and if statements in `R` in your lectures already so you might be able to follow along (if not, don't worry - this is a more complex function than we would expect you to understand for this module):  

```
quality_check <- function(x){

  pass <- 1
  x <- as.data.frame(x)

  # check if numeric
  if((sum(str_detect(x[,2], "1")) < nrow(x)) == TRUE) {pass <- 0}  # check total time is 1
  if(is(x[,3], "numeric") == FALSE){pass <- 0} # pathogen density
  if(is(x[,4], "numeric") == FALSE){pass <- 0} # replication
  if(is(x[,5], "numeric") == FALSE){pass <- 0} # pathogens caught

  # check if character
  if(is(x[,6], "character") == FALSE){pass <- 0} # efficiency
  if((sum(str_detect(x[,6], "[0-9]")) != 0) == TRUE){pass <- 0}
  if((sum(str_detect(x[,6], " ")) != 0) == TRUE){pass <- 0}
  
  # check correct number of observations
  if(nrow(x) < 30){pass <- 0} # 30 rows
  if(length(x) != 6){pass <- 0} # 6 columns

  # check treatments and replications
  if(length(unique(x[,3])) < 5){pass <- 0} # 5 treatments?
  if(length(unique(x[,4])) != 3){pass <- 0} # 3 replications?
  if((max(x[,3]) > 100) == TRUE){pass <- 0} # Does not exceed 100 pathogen density

  # check lowercase
  if((sum(names(x) != tolower(names(x))) != 0) == TRUE){pass <- 0} # are headers correct?
  if((sum(x[,6] != tolower(x[,6])) != 0) == TRUE){pass <- 0}
  
  # check complete
  if(sum(complete.cases(x)) != nrow(x)){pass <- 0} # missing values?

  return(message(ifelse(pass==1, "Passed", "Failed")))
}
```

You see that the function will take your data, then check whether all cells are filled and formatted correctly. Because the function uses square bracket subsetting for identifying columns, the order of the columns is very specific. Finally the data sheets gets assigned a 1 if it passes and a 0 if it fails with a little Pass/Fail message.

Actually, you can check your own data to see if it would pass yourself if you run the above function so that it is saved into your R's memory then running the function itself like `quality_check(<name of your data>)`.

***

### Uploading your dataset to Blackboard

Save your data sheet **as a csv file** (in Excel, click "Save As" and select csv file type). Your file name should be your student number and practical session separated by `_`. e.g. `12345_AM.csv` for the morning session.

Upload your csv file to the assignment link provided on Blackboard. **Only one person in the group needs to upload a file**.

```{r radio2, echo = FALSE}
question_radio(
  "Why do we prefer to use comma separated values files?",
  answer("They save data in a easy to read format with less data loss and smaller file sizes", correct = TRUE),
  answer("They save lots of metadata like colour or font formatting"),
  allow_retry = TRUE
)
```

***

## Final checklist

Use the following check list to make sure you have done everything you need for this practical.  
Have you:

* Uploaded your dataset to Blackboard?
* Done the CA questions?

> That's a wrap! Well done for making it to the end. Check in with your demonstrator.  
> Take a break. Stand up. Dance. Breathe.

One last recap quiz:

```{r hypo, echo = FALSE}
quiz(
question("How many predators are in our experiment?",
         answer("0"),
         answer("1", correct = TRUE),
         answer("2"),
         answer("100"),
         allow_retry = TRUE),
  question_text(
    paste("How many predictor variables are we using?"),
    answer("2", correct = TRUE),
    allow_retry = TRUE
  ),
  question_text(
    paste("How many known constant parameters do we have?"),
    answer("4", correct = TRUE),
    allow_retry = TRUE,
    incorrect = "Constant parameters are values we decide on before running a simulation"
  ),
  question_text(
    paste("How many unknown constant parameters do we have?"),
    answer("2", correct = TRUE),
    allow_retry = TRUE
  )
)

```

***

To sum up, we:

* Composed a theoretic model of a predator-prey interaction with known and unknown parameters. The model describes a set of hypotheses based on assumptions we have made about the predator-prey interaction 
* Identified a biological question and hypothesis
* Designed an experiment with adequate treatments and replication
* Conducted an experiment and recorded data 
* Filled in a spreadsheet with data following the principles of tidy data

All of these steps are part of the scientific method and are relevant to your final assessment.

If everyone follows the instructions, then all your datasets will be comparable and we can combine everyone's data into one giant (anonymised) dataset. Meaning more data to play with than if you had done it by yourself. The idea is that with a large enough sample size (an entire module of students) we can get a good coverage of numbers between 1 and 100 for prey density values.

In the next practical we will be analysing the aggregated & anonymised class data set. We will use another type of statistical models (a linear regression) to statistically describe the data we collect and test the hypotheses of our functional response model.

***

